<HTML>
<HEAD>
<TITLE>GLUE-AI </TITLE>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-2847642-13']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</HEAD>
<BODY>
<h2>Welcome to GLUE.ai!</h2>
<p><i>Open source software for social robots</i></p>
<hr/>

<p>
GLUE.ai is a toolbox of software and specifications used to build open source social robotics systems.
<br/>You can use it to make engaging robot characters, running inside both actual robot hardware, and computer simulations.
<br/>Each character may use a broad combination of physical and verbal features, which may evolve over time in complex, fun, exciting ways.
</p>

<p>
<img src="_image/glue-ai_pals.jpg" width="528" height="408"/>
<br/>(Zeno and Alice images are Copyright Hanson Robokind LLC, used by permission)
</p>

<p>Fun and useful things our characters like to do:
<ul>
<li>Move - expressively, purposefully, naturally</li>
<li>See - people, objects, motion, expressions, gestures</li>
<li>Speak - in a variety of voices and languages</li>
<li>Listen - to speech, music, and other sounds</li>
<li>React and Interact - physically and verbally</li>
<li>Sing and Dance - improvisationally, from memory, and by ear</li>
<li>Teach, Learn, and Play</li>
<li>Behave, Intend, Consider, Emote, and Remember</li>
</ul>
</p>

<p>
Running such characters requires a lot of software and data.  Rather than invent all the pieces ourselves, we bring together existing 
open source software and data standards to make life easier for everyone.   We also divide GLUE.ai itself into a number of separate
pieces, so that our users can each choose just the pieces they need for their own applications.  Each of the subprojects you 
find in our materials also have their own websites:
<a href="http://www.cogchar.org">Cogchar.org</a>, 
<a href="http://www.robokind.org">Robokind.org</a>,
<a href="http://www.rwshop.org">RWShop.org</a>, 
<a href="http://www.appdapter.org">Appdapter.org</a>,
<a href="http://www.jflux.org">JFlux.org</a>,  
<a href="http://www.friendularity.org">Friendularity.org</a>, 
<a href="http://www.storychat.org">StoryChat.org</a>,
<a href="http://www.headyspace.org">HeadySpace.org</a>.
</li>
</p>

<p>
If you are creating content for an existing character application based on GLUE.ai, then you will be primarily interested in our 
authorable content formats, such as:
</p>
<ul>
	<li><a href="http://inform7.com">Inform 7</a> and related Interactive Fiction authoring systems, used only in our StoryChat.org layer and SemPlex authoring tools.
		<ul><li>A relatively simple toolset for folks more interested in storytelling, games, and interaction than in traditional programming.</li>
		<li>Applications that strive to show true "intelligence" may decide not to use this layer, or may use it in unconventional ways.</li>
		</ul>
	</li>
	<li><a href="http://www.w3.org/RDF/">RDF</a> and related Semantic Web, Linked Data, and Description Logic standards.  RDF data may be edited using numerous forms, including
		<ul><li><a href="http://protege.stanford.edu">Protege</a> knowledge editor.  (See also: TopBraid)</li>
			<li>Spreadsheets- including online Google-Docs spreadsheets, as well as local OpenOffice / Excel sheets, and other CSV-compatible editors.</li>
			<li>Plain text forms like Turtle and SPARQL</li>
		</ul>
	</li>
	<li>MIDI, WAV, MP3 and many related musical + audio data standards (used for both sensing input and performance output).</li>
	<li>Camera data and vision processing formats.</li>
	<li>Animation and body description formats, including mappings to robot servos and onscreen displays.</li>
	<li>Other sensor and effector data, including input IMU and location sensing, and output lighting.</li>
	<li>Mathematical definitions of calculations, in a form similar to Matlab, Scilab, or Octave, 
			usually parsed by <a href="https://code.google.com/p/symja">Symja</a>.
	</li>
</ul>
<p>
If you are building your own character software application, you may see GLUE.ai as either simply a library, or as a framework for your app.
<br/>When GLUE.ai is used as a framework, then your application is a set of plugins operating at differing levels of information granularity:
</p>
<ul>
<li>A <b>symbol</b> plugin can process high level information available about the character's mental state and estimated surroundings.  
At this level we shape the intentions of the character.  Usually this kind of plugin will only take action a few times each second, to fulfill its high level decisions,  although it may be thinking continuously.  It relies on input symbols published by lower level signal plugins, and produces output symbols for consumption by other components that translate the symbolic intent into physical/virtual motion, sound, and other character action.</li>
<li>A <b>signal</b> plugin can process lower level streaming information such as camera, audio, and sensor data.  Such a plugin will generally need to run many times each second, to keep up with the streaming data.  This plugin may identify symbolic information in the stream, which it may publish for consideration by higher level symbolic plugins.</li>
<li>Plugins may connect to GLUE.ai components over network protocols (HTTP, AMQP), or be injected directly into our processes via OSGi or equivalents.</li>
<li>Configuration and state data may be shared through repository whiteboards (RDF, SQL, HDF5), and/or explicit messages (Avro, JSON).</li>
</ul>

<p>To get you started, GLUE.ai contains a large number of existing feature components, demonstration programs, and test harnesses.
<br/>All binaries and source code are provided through our subproject websites and repositories.</p>
<p>Please learn more by browsing our online docs:</p>

<ul>
<li><a href="https://www.assembla.com/spaces/glue_ai/wiki">GLUE.ai wiki</a>

	<ul>
	<li><a href="https://www.assembla.com/spaces/glue_ai/wiki/GlueResources">Glue Resources</a> - wiki page showing exhaustive list of resources you might access</li>
	</ul>
</li>
<li>Google Drive docs (easier to access when logged in to Google.com, and even easier when added to your "My Drive" view).
	<ul>
	<li><a href="https://docs.google.com/document/d/1UBLKvDAy_4L9289X_2o_Go050kLdFyp86-wSdNQudqA/edit">README file</a> for this doc tree</li>
	<li><a  href="https://drive.google.com/folderview?id=0B7BjkBoH40tnbUZmcEdUVDludzQ">Glue.ai introduction</a> folder</li>
	<li><a href="https://docs.google.com/document/d/18BC9D9kd7kQDpwSLWoRIIivwEG2PO5Lc1oXe1CCrMzQ/edit">Glue.ai layers</a> - quick overview of our subprojects: Cogchar.org, Appdapter.org, Robokind.org, ...</li>
	<li><a href="https://docs.google.com/spreadsheet/ccc?key=0ArBjkBoH40tndGFZeVlzd1VYUm1mYWRPRU01VllrNXc#gid=0">Glue Ingredients</a>
- reference+status spreadsheet with a row of detail for each subproject</li>
<li><a href="https://drive.google.com/folderview?id=0B7BjkBoH40tnYzc4YzY4MmUtYmRhNi00OTE4LWI4ODctNjUzMzcxMjU4ZjZl">Open Src Glue</a> - Full Google Drive doc folder for all subprojects (but some subprojects have more docs in wikis or under the "Volume 1 - GLUE.ai Intro" folder linked above, so please don't be discouraged if some subfolders here appear thin+rough.)
	</ul>
</li>

<li><a href="http://www.hrkind.com">HRKind.com website</a> Tech docs from a sponsor's commercial products that use Glue.AI</li>
</BODY>
</HTML>
